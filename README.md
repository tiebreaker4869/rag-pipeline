# RAG Pipeline

A multi-modal RAG pipeline for long-document understanding on the MMLongBench-Doc dataset.

## Features

- **Multiple Pipeline Types**: TextRAG, MultimodalRAG, MultimodalRAGOnline, MultimodalRAGLLMRerank
- **Vision + Text Retrieval**: ColPali embeddings + FAISS vector search
- **Flexible Reranking**: BGE cross-encoder or LLM-based reranking
- **Multiple LLMs**: Gemini and OpenAI support

## Installation

```bash
uv venv
source .venv/bin/activate
uv pip install -e .
```

## Quick Start

### 1. Set API Keys

```bash
export GOOGLE_API_KEY="your-key"
export OPENAI_API_KEY="your-key"  # optional
```

### 2. Prepare Data

Organize documents in subdirectories:
```
data/MMLongBench-Doc/data/documents/
├── doc1/
│   ├── doc1.pdf
│   ├── doc1_page_1.md  # generated by OCR
│   └── embeddings.pt    # generated for multimodal
└── doc2/
    └── ...
```

Generate OCR markdown:
```bash
python scripts/offline_ocr.py --input_dir data/MMLongBench-Doc/data/documents
```

Generate vision embeddings (for multimodal pipelines):
```bash
python src/rag_pipeline/embeddings/generate_embeddings.py --doc_dir <path>
```

### 3. Run Inference

```bash
python scripts/run_inference.py \
    --config configs/multimodal_rag.yaml \
    --data_file data/MMLongBench-Doc/data/samples.json \
    --doc_dir data/MMLongBench-Doc/data/documents \
    --output_file output/predictions.json
```

### 4. Evaluate

```bash
# Get accuracy scores
python scripts/llm_judge.py \
    --predictions_file output/predictions.json \
    --ground_truth_file data/MMLongBench-Doc/data/samples.json \
    --output_file output/eval.json

# Analyze by evidence type
python scripts/analyze_results.py \
    --eval_results output/eval.json \
    --samples_file data/MMLongBench-Doc/data/samples.json
```

## Configuration

Edit YAML files in [configs/](configs/) to customize:

- [text_rag.yaml](configs/text_rag.yaml) - Text-only retrieval
- [multimodal_rag.yaml](configs/multimodal_rag.yaml) - Vision + text (pre-computed embeddings)
- [multimodal_rag_online.yaml](configs/multimodal_rag_online.yaml) - Vision + text (on-the-fly parsing)
- [multimodal_rag_llm_rerank.yaml](configs/multimodal_rag_llm_rerank.yaml) - With LLM reranking

## Project Structure

```
├── configs/              # Pipeline configurations
├── src/rag_pipeline/
│   ├── pipelines/       # 4 pipeline implementations
│   ├── retrievers/      # ColPali + vector retrieval
│   ├── rerankers/       # BGE + LLM rerankers
│   ├── llm/             # Gemini/OpenAI integrations
│   └── parsers/         # PDF parsing
├── scripts/             # Inference & evaluation
└── data/                # Documents & questions
```

## Performance

Results on MMLongBench-Doc (1,082 samples):

| Pipeline | Accuracy |
|----------|----------|
| TextRAG | 36.78% |
| MultimodalRAG | 37.71% |
| MultimodalRAGOnline | **39.09%** |
| MultimodalRAGLLMRerank | **39.09%** |

